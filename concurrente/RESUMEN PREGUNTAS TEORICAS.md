
--------------------------------------------------------------------------------
Programaci√≥n Concurrente 2025
Cuestionario gu√≠a - Clases Te√≥ricas 5, 6 y 7
## 1- Defina y diferencie programa concurrente, programa distribuido y programa paralelo.
Los tres t√©rminos describen diferentes aspectos de la ejecuci√≥n y el dise√±o de programas:
üí° Definiciones:
‚Ä¢ Programa Concurrente: Se refiere a la ejecuci√≥n de m√∫ltiples tareas o procesos de manera aparentemente simult√°nea, aunque no necesariamente en paralelo
. Puede llevarse a cabo en sistemas con un solo procesador (mediante la alternancia r√°pida de tareas, conocido como multiprogramaci√≥n) o en sistemas con m√∫ltiples procesadores. Especificar la concurrencia implica definir los procesos concurrentes, su comunicaci√≥n y su sincronizaci√≥n
.
‚Ä¢ Programa Paralelo: Es la ejecuci√≥n concurrente en m√∫ltiples procesadores con el objetivo principal de reducir el tiempo de ejecuci√≥n del programa
.
‚Ä¢ Programa Distribuido: Es fundamentalmente un programa concurrente que se comunica mediante mensajes
. T√≠picamente, supone la ejecuci√≥n sobre una arquitectura de memoria distribuida, aunque podr√≠a ejecutarse sobre una de memoria compartida o h√≠brida. Los procesos en un programa distribuido SOLO comparten canales (f√≠sicos o l√≥gicos), y nada m√°s
--------------------------------------------------------------------------------

## 2- Marque al menos 2 similitudes y 2 diferencias entre los pasajes de mensajes sincr√≥nicos y asincr√≥nicos. Indicar cual es la principal ventaja de pasaje de mensajes sincr√≥nicos respecto a pasaje de mensajes asincr√≥nicos.
Ambos son mecanismos fundamentales para el Pasaje de Mensajes (PM) utilizados en el procesamiento distribuido
.
Similitudes (Al menos 2)
1. Mecanismos de Interacci√≥n: Ambos utilizan primitivas de env√≠o (Send o sync_send) y recepci√≥n (Receive) para que los procesos interact√∫en
.
2. Canales Compartidos: En ambos modelos, los procesos solo comparten canales (f√≠sicos o l√≥gicos) para la comunicaci√≥n
.
3. Naturaleza Bloqueante del Receive: En ambos casos (PMA y PMS), la primitiva de recepci√≥n (Receive o ? en CSP) es bloqueante, demorando al receptor hasta que haya un mensaje en el canal
.
Diferencias (Al menos 2)
1. Comportamiento del Emisor (Send):
    ‚ó¶ PMA: La operaci√≥n Send no bloquea al emisor, el proceso contin√∫a inmediatamente despu√©s de enviar el mensaje
.
    ‚ó¶ PMS: La operaci√≥n Send o sync_send es bloqueante; el transmisor queda esperando hasta que el mensaje sea recibido por el receptor
.
2. Uso de Memoria/Canales:
    ‚ó¶ PMA: Los canales son colas de mensajes (buffers) que se consideran ilimitadas en principio, almacenando mensajes enviados y a√∫n no recibidos
.
    ‚ó¶ PMS: La cola de mensajes asociada a un Send sobre un canal se reduce a un mensaje, lo que requiere menos memoria
.
3. Grado de Concurrencia y Deadlock:
    ‚ó¶ PMA: Hay una mayor concurrencia porque los procesos se ejecutan a su propia velocidad gracias al buffering impl√≠cito
.
    ‚ó¶ PMS: El grado de concurrencia se reduce (los emisores se bloquean), y las posibilidades de deadlock son mayores, requiriendo que el programador asegure que todas las sentencias send y receive hagan matching
.
Ventaja Principal de PMS
La principal ventaja del Pasaje de Mensajes Sincr√≥nicos respecto al Asincr√≥nico es que requiere menos memoria, ya que la cola de mensajes se reduce a un solo mensaje


--------------------------------------------------------------------------------
## 3- Analice qu√© tipo de mecanismos de pasaje de mensajes son m√°s adecuados para resolver problemas de tipo Cliente/Servidor, Pares que interact√∫an, Filtros, y Productores y Consumidores. Justifique claramente su respuesta.
üéØ Filtros y Productores y Consumidores
‚Ä¢ Mecanismo Adecuado: Pasaje de Mensajes Asincr√≥nicos (PMA) o Pasaje de Mensajes General
.
‚Ä¢ Justificaci√≥n: El Pasaje de Mensajes (PM) se ajusta bien a estos problemas, ya que generalmente plantean una comunicaci√≥n unidireccional
. PMA es especialmente ventajoso para Productores/Consumidores porque el buffering impl√≠cito (canales como colas ilimitadas) permite a los procesos ejecutar a su propia velocidad, sin ir al ritmo del m√°s lento, lo que aumenta la concurrencia. Los filtros (procesos que reciben de canales de entrada y env√≠an a canales de salida) tambi√©n se benefician del PMA para mantener un flujo de datos eficiente. Si se usara PMS, ser√≠a necesario programar un proceso buffer adicional para lograr el mismo efecto
.
üéØ Pares que interact√∫an
‚Ä¢ Mecanismo Adecuado: Pasaje de Mensajes General (PMA o PMS)
.
‚Ä¢ Justificaci√≥n: Al igual que los filtros, los pares que interact√∫an (procesos id√©nticos que interact√∫an entre s√≠) a menudo requieren comunicaci√≥n unidireccional o intercambios simples que el PM gestiona bien
. Si la interacci√≥n requiere un intercambio sim√©trico de valores (bidireccional), PMS con comunicaci√≥n guardada puede ser utilizado para evitar deadlock, aunque puede ser m√°s complejo de implementar que una soluci√≥n PMA
.
üéØ Cliente/Servidor (C/S)
‚Ä¢ Mecanismo M√°s Adecuado: RPC (Remote Procedure Call) y Rendezvous
.
‚Ä¢ Justificaci√≥n: Para resolver C/S se necesita comunicaci√≥n bidireccional (solicitud y respuesta). Si se usa PM simple (PMA), esto obliga a especificar dos tipos de canales (requerimientos y respuestas), y cada cliente necesita un canal de reply distinto
. RPC y Rendezvous resuelven esta complejidad, ya que son t√©cnicas que suponen un canal bidireccional de forma impl√≠cita y combinan una interfaz procedural (similar a monitores) con mensajes sincr√≥nicos que demoran al llamador hasta el retorno de los resultados
.

--------------------------------------------------------------------------------
## 4- Indique por qu√© puede considerarse que existe una dualidad entre los mecanismos de monitores y pasaje de mensajes. Ejemplifique
Existe una dualidad entre monitores y pasaje de mensajes (PM) porque cada uno de ellos es capaz de simular al otro
. Esta correspondencia entre sus mecanismos es directa
La elecci√≥n de cu√°l mecanismo es m√°s eficiente depende de la arquitectura f√≠sica subyacente: los monitores son adecuados para arquitecturas de Memoria Compartida (MC), mientras que PM es m√°s eficiente para arquitecturas de Memoria Distribuida (MD)
.
Ejemplo de Simulaci√≥n (Monitor Activo con PM - C/S)
Un monitor (que es un manejador de recurso con variables permanentes y procedures pasivos) puede ser simulado usando un proceso servidor activo y Pasaje de Mensajes
.
Programas con Monitores
	
Programas basados en PM (Servidor Activo)
Variables permanentes
	
Variables locales del servidor (encapsulan el estado)
.
Llamado a procedure
	
send al canal de requerimiento y luego receive del canal de respuesta propio
.
Entry del monitor
	
receive request() (el servidor espera por un pedido)
.
Retorno del procedure
	
send respuesta() (el servidor devuelve el resultado)
.
Sentencia wait
	
Se simula salvando el pedido pendiente (diferir la respuesta)
.
Sentencia signal
	
Se simula recuperando/procesando el pedido pendiente y enviando la respuesta
.
Ejemplo Concreto (Administrador de Recursos): Para simular el monitor Administrador_Recurso que maneja la adquisici√≥n y liberaci√≥n de unidades (incluyendo sincronizaci√≥n por condici√≥n), el servidor utiliza una cola (queue pendientes) para salvar los pedidos de adquisici√≥n cuando no hay unidades disponibles (wait en monitor). Cuando se libera una unidad (signal en monitor), el servidor recupera un pedido de esa cola para atenderlo

--------------------------------------------------------------------------------
## 5- ¬øEn qu√© consiste la comunicaci√≥n guardada (introducida por CSP) y cu√°l es su utilidad? Describa c√≥mo es la ejecuci√≥n de sentencias de alternativa e iteraci√≥n que contienen comunicaciones guardadas.
¬øEn qu√© consiste y cu√°l es su utilidad?
La comunicaci√≥n guardada (introducida por CSP, Communicating Sequential Processes) consiste en utilizar operaciones de comunicaci√≥n (? para entrada o ! para salida) dentro de una guarda, permitiendo hacer un AWAIT hasta que una condici√≥n sea verdadera
.
Una guarda se compone de una condici√≥n booleana opcional (B) y una sentencia de comunicaci√≥n (C), resultando en la forma B;C‚ÜíS
.
Su principal utilidad es soportar la comunicaci√≥n no determin√≠stica
. Esto es crucial cuando un proceso necesita comunicarse con otros (posiblemente por diferentes puertos) sin saber de antemano el orden en que los otros procesos desear√°n comunicarse con √©l
.
‚Ä¢ Una guarda tiene √©xito si B es true y ejecutar C no causa demora
.
‚Ä¢ Una guarda falla si B es false
.
‚Ä¢ Una guarda se bloquea si B es true pero C no puede ejecutarse inmediatamente
.
‚öôÔ∏è Ejecuci√≥n de Sentencias de Alternativa (if) e Iteraci√≥n (do)
Las sentencias de comunicaci√≥n guardadas aparecen en las estructuras if y do de CSP
.
1. Evaluaci√≥n de las Guardas
‚Ä¢ Se eval√∫an primero todas las guardas
‚Ä¢ Si todas las guardas fallan, el if termina sin efecto (o el do termina)
‚Ä¢ Si al menos una guarda tiene √©xito, se elige una de ellas de forma no determin√≠stica
‚Ä¢ Si algunas guardas se bloquean, el proceso espera hasta que alguna de ellas tenga √©xito (es decir, hasta que la comunicaci√≥n pueda ocurrir inmediatamente)

2. Ejecuci√≥n de la Comunicaci√≥n:
‚Ä¢ Luego de elegir una guarda exitosa, se ejecuta la sentencia de comunicaci√≥n de la guarda elegida

3. Ejecuci√≥n de la Sentencia:
‚Ä¢ Finalmente, se ejecuta la sentencia Si‚Äã asociada a esa guarda
La ejecuci√≥n de la sentencia de iteraci√≥n (do) es similar, repiti√©ndose este ciclo hasta que todas las guardas fallen, momento en el cual la iteraci√≥n termina
--------------------------------------------------------------------------------
## 6- Modifique la soluci√≥n con mensajes sincr√≥nicos de la Criba de Erat√≥stenes para encontrar los n√∫meros primos detallada en teor√≠a de modo que los procesos no terminen en deadlock.
La soluci√≥n original de la Criba de Erat√≥stenes con Pasaje de Mensajes Sincr√≥nicos (PMS) establece un pipeline de procesos filtro
. La fuente indica que, excepto el primer proceso, los dem√°s terminan bloqueados esperando un mensaje de su predecesor cuando se acaba la entrada, lo que es una forma de no-terminaci√≥n controlada (deadlock potencial si no se maneja)
.
Para evitar que los procesos terminen en deadlock y garantizar una terminaci√≥n limpia, se debe introducir un centinela (sentinel) que marque el fin del flujo de datos
. Asumiremos que N es el l√≠mite superior y 0 es el centinela, ya que los primos son positivos.
üìù Soluci√≥n Original (Base para la modificaci√≥n)
:

Process Criba[1]  {    int p = 2;
    for [i = 3 to n by 2]  Criba[2] ! (i); 
}
Process Criba[i = 2 to L]  {    int p, proximo;
    Criba[i-1] ? (p); 
    do Criba[i-1] ? (proximo) ‚Üí
        if ((proximo MOD p) <> 0 ) and (i < L) ‚Üí Criba[i+1] ! (proximo); 
    od
}

‚úÖ Soluci√≥n Modificada (Usando Centinela):
1. Proceso Criba
 (Productor): Debe enviar el centinela (0) al terminar el stream.

Process Criba[1]  {    int p = 2;
    for [i = 3 to n by 2]  Criba[2] ! (i); 
    Criba[2] ! (0); // Env√≠a el centinela para se√±alar el fin
}

2. Proceso Criba[i] (Filtro, i ‚â• 2): Debe recibir mensajes y, si detecta el centinela, propagarlo a su sucesor y terminar su propio loop, evitando quedar bloqueado esperando una entrada inexistente.

Process Criba[i = 2 to L]  {    int p, proximo;
    Criba[i-1] ? (p); 
    // p es el primo detectado por este filtro
    
    do Criba[i-1] ? (proximo) ‚Üí
        if (proximo == 0) and (i < L) ‚Üí 
            Criba[i+1] ! (0); // Propaga el centinela si no es el √∫ltimo filtro
            break; // Termina el loop para que el proceso Criba[i] finalice
        fi
        
        if ((proximo MOD p) <> 0 ) and (i < L) ‚Üí 
            Criba[i+1] ! (proximo); // Env√≠a n√∫meros no m√∫ltiplos
        // El √∫ltimo proceso (i=L) no intenta enviar nada
    od
}

Al incluir el centinela y manejar su propagaci√≥n, se asegura que la cadena de procesos termine ordenadamente en lugar de bloquearse indefinidamente esperando datos.

--------------------------------------------------------------------------------
## 7- Suponga que N procesos poseen inicialmente cada uno un valor. Se debe calcular la suma de todos los valores y al finalizar la computaci√≥n todos deben conocer dicha suma.
a) An√°lisis (desde el punto de vista del n√∫mero de mensajes y la performance global)
Este an√°lisis se basa en la informaci√≥n proporcionada en las fuentes para el problema de encontrar el m√≠nimo y el m√°ximo valor, el cual sigue un patr√≥n de intercambio de valores similar al de la suma
.
Arquitectura
	
N√∫mero de Mensajes
	
Performance Global y Justificaci√≥n
Estrella (Centralizada)
	
2(N‚àí1) mensajes
.
	
Eficaz para la toma de decisiones centralizadas
. La performance puede verse afectada ya que los N‚àí1 mensajes llegan al coordinador casi simult√°neamente. El coordinador es un punto √∫nico de fallo. La latencia puede ser alta, aunque el n√∫mero de mensajes es lineal
.
Anillo Circular
	
(2N)‚àí1 mensajes
.
	
El n√∫mero de mensajes es lineal (similar a la centralizada)
. Sin embargo, el esquema de comunicaci√≥n es inherentemente lineal y lento para este tipo de problema. La soluci√≥n requiere que los mensajes circulen dos veces completas por el anillo, lo que lleva a tiempos muy diferentes que la centralizada, ya que cada proceso espera secuencialmente
.
Totalmente Conectada (Sim√©trica)
	
N(N‚àí1) mensajes
.
	
Utiliza el mayor n√∫mero de mensajes si no se dispone de broadcast
. Todos los procesos ejecutan el mismo algoritmo, y todos tienen acceso a todos los datos. Si la red soporta transmisiones concurrentes, puede ser muy r√°pida (shortest), pero el overhead de comunicaci√≥n limita el speedup. Si se dispone de primitiva broadcast, el n√∫mero de mensajes se reduce a N
.
√Årbol y Grilla Bidimensional
	
(No detallado en las fuentes).
	
Las fuentes mencionan √°rboles y grafos para estructuras din√°micas y b√∫squedas
, y el paradigma pipeline y heartbeat se usan para c√°lculos en cuadr√≠culas
. Sin embargo, las fuentes no proporcionan un an√°lisis expl√≠cito del n√∫mero de mensajes o la performance global para el problema de la suma en arquitecturas de √Årbol o Grilla Bidimensional.
b) Escriba las soluciones para las arquitecturas mencionadas.
Adaptaremos los ejemplos de intercambio de valores de las fuentes (basados en PMA) para el c√°lculo de la suma.
1. Arquitectura en Estrella (Centralizada)
Un proceso central (P) recopila todos los valores, calcula la suma y la reenv√≠a.

chan valores(int), resultados[n-1] (int sumaTotal);

Process P { 
    int v; // Valor inicial de P
    int nuevo;
    int suma = v;
    
    for [i=1 to n-1] { 
        receive valores (nuevo); 
        suma = suma + nuevo; 
    } 
    
    // El procesador central propaga la suma total
    for [i=1 to n-1] 
        send resultados [i-1] (suma);
}

Process P[i=1 to n-1] { 
    int v; // Valor inicial de P[i]
    int sumaTotal;
    
    send valores (v); // Env√≠a valor al central
    receive resultados[i-1](sumaTotal); // Recibe la suma total
}

2. Arquitectura Totalmente Conectada (Sim√©trica)
Cada proceso env√≠a su valor local a todos los dem√°s y recibe N‚àí1 valores, calculando la suma total de forma paralela
.

chan valores[n] (int);

Process P[i=0 to n-1]  { 
    int v=...; // Valor inicial de P[i]
    int nuevo;
    int suma = v;
    
    // Enviar valor local a todos los dem√°s
    for [k=0 to n-1 st k <> i ] 
        send valores[k] (v);
    
    // Recibir valores de todos los dem√°s
    for [k=0 to n-1 st k <> i ] { 
        receive valores[i] (nuevo); 
        suma = suma + nuevo; // Acumular la suma
    } 
    // Al finalizar, 'suma' contiene la suma total en P[i].
}

3. Arquitectura en Anillo Circular
Se utiliza un esquema de dos etapas: una pasada para acumular la suma y una segunda pasada para propagar la suma total
.

chan valor_suma[n] (int);

Process P  { 
    int v=...; // Valor inicial de P
    int suma_recibida;
    
    // Etapa 1: P arranca la acumulaci√≥n (send valor inicial)
    send valor_suma[1] (v);
    receive valor_suma (suma_recibida); // P recibe la suma total
    
    // Etapa 2: Propagar la suma total
    send valor_suma[1] (suma_recibida);
    // P tiene la suma en 'suma_recibida'.
}

Process P[i=1 to n-1]  { 
    int v=...; // Valor inicial de P[i]
    int suma_recibida;
    
    // Etapa 1: Acumular
    receive valor_suma[i] (suma_recibida);
    suma_recibida = suma_recibida + v;
    send valor_suma[(i+1) mod n] (suma_recibida);
    
    // Etapa 2: Recibir y Propagar la suma final
    receive valor_suma[i] (suma_recibida);
    if (i < n-1) 
        send valor_suma[i+1] (suma_recibida);
    // P[i] tiene la suma en 'suma_recibida'.
};

Nota sobre √Årbol y Grilla Bidimensional: Las soluciones espec√≠ficas para calcular la suma total en arquitecturas de √Årbol y Grilla Bidimensional no est√°n disponibles en las fuentes proporcionadas.

--------------------------------------------------------------------------------
## 8- Marque similitudes y diferencias entre los mecanismos RPC y Rendezvous. Ejemplifique para la resoluci√≥n de un problema a su elecci√≥n.
RPC (Remote Procedure Call) y Rendezvous son mecanismos de comunicaci√≥n y sincronizaci√≥n dise√±ados principalmente para el patr√≥n Cliente/Servidor
.
Similitudes
1. Patr√≥n C/S: Ambos son ideales para programar aplicaciones Cliente/Servidor
.
2. Interfaz Procedural: Ambos combinan una interfaz "tipo monitor" (llamadas externas CALL)
.
3. Sincron√≠a Impl√≠cita: Ambos utilizan mensajes sincr√≥nicos de manera impl√≠cita, demorando al llamador (cliente) hasta que la operaci√≥n remota termine de ejecutarse y se devuelvan los resultados
.
4. Canal Bidireccional: Ambos suponen un canal bidireccional para manejar la solicitud y la respuesta
.
Diferencias (Difieren en c√≥mo se sirve la invocaci√≥n)
Caracter√≠stica
	
RPC (Remote Procedure Call)
	
Rendezvous
Servicio de Invocaci√≥n
	
Crea un nuevo proceso (servidor) para manejar conceptualmente cada llamado
.
	
Hace rendezvous con un proceso existente (el proceso servidor √∫nico)
.
Sincronizaci√≥n Interna
	
Solo provee comunicaci√≥n interm√≥dulo. La Exclusi√≥n Mutua y Sincronizaci√≥n por Condici√≥n deben programarse aparte dentro del m√≥dulo
.
	
Combina comunicaci√≥n y sincronizaci√≥n
. Las operaciones se atienden t√≠picamente una por vez (secuencialmente)
.
Mecanismo de Servicio
	
El servidor implementa procedures (proc opname) llamados remotamente
.
	
El servidor utiliza una sentencia de Entrada (in o accept) para esperar, procesar la invocaci√≥n y devolver los resultados
.
Vista del Cliente
	
El cliente siente que tiene el proceso remoto en su sitio
.
	
El cliente invoca un call a un proceso activo existente
.
Ejemplo: Buffer Limitado con Rendezvous
El problema del Buffer Limitado ilustra claramente c√≥mo Rendezvous combina comunicaci√≥n y sincronizaci√≥n usando un √∫nico proceso servidor y comunicaci√≥n guardada, algo que RPC no logra por s√≠ mismo
.
En este ejemplo, el proceso Buffer (servidor) solo atiende depositar si la capacidad es menor a N, y solo atiende retirar si la capacidad es mayor a 0, garantizando la sincronizaci√≥n y exclusi√≥n mutua impl√≠citamente
.

module BufferLimitado
op depositar (typeT), retirar (OUT typeT);
body .
process Buffer
{ queue buf;
int cantidad = 0;
while (true)
{  
    in depositar (item) and cantidad < n ‚Üí   // Guarda: solo acepta si hay espacio
        push (buf, item);
        cantidad = cantidad + 1;
    ÔÉ∞ retirar (OUT item) and cantidad > 0 ‚Üí   // Guarda: solo acepta si hay elementos
        pop (buf, item);
        cantidad = cantidad - 1;
    ni
}
}
end BufferLimitado

‚Ä¢ Cliente (Llamador): Un proceso cliente simplemente har√≠a call BufferLimitado.depositar(dato)
.
‚Ä¢ Servidor (Buffer): El proceso Buffer espera en la sentencia in. Si ambas guardas son exitosas, elige no determin√≠sticamente cu√°l atender
. Una vez que se elige la entrada (ej: depositar), se ejecuta el c√≥digo asociado, y solo entonces el cliente llamador puede continuar.

## 9- Describa sint√©ticamente las caracter√≠sticas de sincronizaci√≥n y comunicaci√≥n de ADA. Indicar que diferencia hay entre la comunicaci√≥n guardada de Rendezvous (general) con la provista por ADA.
üéØ Caracter√≠sticas de Sincronizaci√≥n y Comunicaci√≥n en ADA
ADA, desarrollado por el Departamento de Defensa de USA, utiliza el modelo de tareas para la concurrencia
. Sus principales caracter√≠sticas son:
1. Tasks (Tareas): El programa se organiza en tareas que pueden ejecutarse independientemente y contienen primitivas de sincronizaci√≥n
.
1. Rendezvous: Es el mecanismo principal de sincronizaci√≥n y comunicaci√≥n
. Es un mecanismo sincr√≥nico
.
1. Entrys: Son los puntos de invocaci√≥n de una tarea, especificados en la parte visible (header) de la misma
.
1. Entry Call: Los procesos cliente invocan una operaci√≥n usando un entry call (Tarea.entry (par√°metros)), el cual es bloqueante y demora al llamador hasta que la operaci√≥n termine
.
1. Accept: La tarea servidora utiliza la primitiva accept para servir los llamados a un entry espec√≠fico
. La tarea se demora hasta que haya una invocaci√≥n pendiente para ese entry
.
1. Sentencia Wait Selectiva: Soporta la comunicaci√≥n guardada mediante la estructura select
.
üîÑ Diferencia entre Comunicaci√≥n Guardada de Rendezvous (General) y ADA
El Rendezvous general, como se describe en las fuentes (por ejemplo, en el contexto de m√≥dulos con la sintaxis in...ni), y la implementaci√≥n en ADA cumplen la misma funci√≥n: permitir la espera selectiva no determin√≠stica sobre m√∫ltiples invocaciones de operaciones, posiblemente condicionadas
.
La diferencia clave radica en la sintaxis y las capacidades de control directo sobre la selecci√≥n:
Caracter√≠stica
	
Rendezvous General (Sintaxis in...ni)
	
Rendezvous en ADA (Sintaxis select...accept)
Estructura
	
Utiliza in opname (formales) and B by e ‚Üí S; ni
.
	
Utiliza select when B => accept E; sentencias; or... end select;
.
Expresi√≥n de Sincronizaci√≥n (Guarda)
	
Se define como Bi‚Äã (opcional) dentro de la alternativa
.
	
Se define con la cl√°usula WHEN (opcional) antes del ACCEPT
.
Expresi√≥n de Scheduling
	
Puede incluir una expresi√≥n de scheduling opcional (ei‚Äã) para influir en la elecci√≥n del llamador
.
	
Utiliza atributos del entry como count para la gesti√≥n
, pero el mecanismo by e no est√° directamente detallado en la sintaxis provista para select/accept.
En resumen, ADA implementa la comunicaci√≥n guardada mediante su sentencia select junto con la primitiva accept y la cl√°usula when para las condiciones
, mientras que la descripci√≥n general del Rendezvous usa la estructura in...ni con la posibilidad expl√≠cita de expresiones de sincronizaci√≥n (Bi‚Äã) y scheduling (ei‚Äã)
.

--------------------------------------------------------------------------------

## 10- Considere el problema de lectores/escritores. Desarrolle un proceso servidor para implementar el acceso a la base de datos, y muestre las interfaces de los lectores y escritores con el servidor. Los procesos deben interactuar: a) con mensajes asincr√≥nicos; b) con mensajes sincr√≥nicos; c) con RPC; d) con Rendezvous.
El problema de Lectores/Escritores requiere un proceso Servidor (o Scheduler) que controle el acceso a una base de datos (BD). Los lectores pueden acceder concurrentemente, pero los escritores deben tener acceso exclusivo
.
El servidor debe exponer las siguientes cuatro operaciones, independientemente del mecanismo:
1. InicioLeer: Petici√≥n de un lector.
2. FinLeer: Notificaci√≥n de que un lector ha terminado.
3. InicioEscribir: Petici√≥n de un escritor.
4. FinEscribir: Notificaci√≥n de que un escritor ha terminado.
El estado interno del servidor necesita una variable para contar los lectores activos (numLect)
.
a) Soluci√≥n con Mensajes Asincr√≥nicos (PMA)
Para implementar el patr√≥n Cliente/Servidor con PMA, necesitamos un canal de requerimientos general y canales de respuesta privados para cada cliente
. La implementaci√≥n simula un monitor activo
.
Definiciones de Canales: Necesitamos identificar al cliente y el tipo de operaci√≥n
.

type clase_op = enum(InicioLeer, FinLeer, InicioEscribir, FinEscribir);
// Respuesta simple (ACK) o tipo de dato de la BD si la BD fuera accesible
chan request (int idCliente, clase_op oper); 
chan respuesta[n] (); // Array de canales de respuesta, uno por cliente

Interfaz del Cliente (Lector/Escritor):

Process Lector [i = 1 to n] {
    // 1. Pide empezar a leer
    send request(i, InicioLeer);
    receive respuesta[i](); 
    // ... Usa la BD ...
    // 2. Notifica el fin de la lectura
    send request(i, FinLeer); 
    receive respuesta[i](); 
}

Process Escritor [i = 1 to n] {
    // 1. Pide empezar a escribir
    send request(i, InicioEscribir);
    receive respuesta[i]();
    // ... Usa la BD (exclusivamente) ...
    // 2. Notifica el fin de la escritura
    send request(i, FinEscribir);
    receive respuesta[i]();
}

Proceso Servidor (Scheduler) (Simplificado, adaptando la l√≥gica de
 para salvar pedidos):
El servidor debe usar un mecanismo para salvar pedidos pendientes (wait) si no se puede acceder inmediatamente, y luego recuperar/procesar el pedido (signal) cuando se libere el recurso
. Necesitar√≠a colas internas para lectores y escritores pendientes.

Process Sched {
    int numLect = 0;
    queue pendientesEscritores, pendientesLectores;
    
    while (true) {
        // Recibe cualquier tipo de requerimiento
        receive request (IdCliente, oper); 
        
        if (oper == InicioLeer) {
            // L√≥gica para InicioLeer: solo si no hay escritores esperando
            // ... (Se debe implementar l√≥gica de prioridad) ... 
            // Si el acceso es posible: 
            numLect = numLect + 1;
            send respuesta[IdCliente](); // Permite la lectura

            // Si el acceso NO es posible, guardar IdCliente en pendientesLectores
            // (Esta l√≥gica de guardado es compleja y requiere definir el criterio de espera) [17, 18].

        } elsif (oper == InicioEscribir) {
            if (numLect == 0) {
                numLect = -1; // Marcador para exclusividad de escritor
                send respuesta[IdCliente]();
            } else {
                push (pendientesEscritores, IdCliente); // Salvar pedido pendiente [15]
            }
        } elsif (oper == FinLeer) {
            numLect = numLect - 1;
            send respuesta[IdCliente]();
            // L√≥gica para despertar escritores pendientes si numLect llega a 0 [18].
        } elsif (oper == FinEscribir) {
            // L√≥gica para despertar lectores/escritores pendientes [18].
            numLect = 0; // Liberar recurso
            send respuesta[IdCliente]();
        }
    }
}

b) Soluci√≥n con Mensajes Sincr√≥nicos (PMS)
Utilizar PMS directamente es m√°s complejo para C/S
, especialmente cuando se requiere demorar el servicio (como en InicioEscribir si hay lectores), ya que las primitivas son bloqueantes y el Send del cliente se detiene hasta que el servidor recibe el mensaje
.
La principal desventaja es que, si un lector (L) env√≠a FinLeer (liberando el recurso), L se detiene hasta que el servidor recibe el mensaje, aunque no haya raz√≥n para la demora
. Para una soluci√≥n pura en PMS que maneje la sincronizaci√≥n de manera eficiente, se requerir√≠a un proceso buffer adicional para desacoplar el emisor del receptor
.
c) Soluci√≥n con RPC (Remote Procedure Call)
RPC es ideal para C/S porque combina la interfaz procedural (como un monitor) con mensajes sincr√≥nicos bidireccionales impl√≠citos
. El servidor se implementa como un M√≥dulo que exporta procedimientos
.
M√≥dulo Servidor (Scheduler):
El m√≥dulo exporta los cuatro procedimientos. Asumiendo que los procesos dentro del m√≥dulo ejecutan concurrentemente, se necesitar√≠a sincronizaci√≥n interna (monitores o sem√°foros) para proteger la variable numLect
.

module Scheduler
op InicioLeer (INT idCliente);
op FinLeer (INT idCliente);
op InicioEscribir (INT idCliente);
op FinEscribir (INT idCliente);

body
INT numLect = 0;
SEM mutex = 1; // Para EM sobre numLect
SEM espera_escritor = 0; // Para sincronizaci√≥n
...
proc InicioLeer (idCliente) {
    P(mutex);
    // L√≥gica de espera si hay escritores
    V(mutex);
}
... // Definiciones similares para FinLeer, InicioEscribir, FinEscribir
end Scheduler;

Interfaz del Cliente (Lector/Escritor):
El cliente llama al procedimiento remoto como si fuera un procedimiento local
.

Process Lector [i = 1 to n] {
    // 1. Pide empezar a leer
    call Scheduler.InicioLeer(i);
    // ... Usa la BD ...
    // 2. Notifica el fin de la lectura
    call Scheduler.FinLeer(i); 
}

Process Escritor [i = 1 to n] {
    // 1. Pide empezar a escribir
    call Scheduler.InicioEscribir(i);
    // ... Usa la BD ...
    // 2. Notifica el fin de la escritura
    call Scheduler.FinEscribir(i);
}

d) Soluci√≥n con Rendezvous
Rendezvous combina comunicaci√≥n y sincronizaci√≥n, y el servicio lo brinda un proceso existente activo
. Utiliza comunicaci√≥n guardada (in/ni o select/accept) para manejar la selecci√≥n no determin√≠stica y las condiciones de acceso
.
El esquema de Rendezvous para Lectores/Escritores es proporcionado en las fuentes, utilizando la sintaxis de ADA
:
Estructura del Servidor (Task Sched):
El servidor utiliza la variable numLect para controlar el acceso y las guardas when para condicionar los accept
. El InicioEscribir solo se acepta si numLect es cero, o si no hay peticiones pendientes de otros escritores (InicioEscribir'Count = 0).

Task body Sched is
    numLect: integer := 0; // Contador de lectores
Begin
    Loop
        Select
            // Condici√≥n para Lectores: Si NO hay escritores esperando (count=0)
            When InicioEscribir'Count = 0 => 
                accept InicioLeer; // Permite la lectura
                numLect := numLect+1;
            or accept FinLeer; 
                numLect := numLect-1;
            // Condici√≥n para Escritores: Si NO hay lectores activos (numLect=0)
            or When numLect = 0 => 
                accept InicioEscribir; // Bloquea y espera al escritor
                accept FinEscribir; // Espera a que el escritor termine
                
                // L√≥gica para despertar lectores encolados despu√©s de la escritura
                For i in 1..InicioLeer‚Äòcount loop 
                    accept InicioLeer;
                    numLect:= numLect +1;
                End loop;
        End select;
    End loop;
End Sched;

Interfaz del Cliente (Lector/Escritor):
Los clientes realizan un entry call
.

// Lector
Loop
    Sched.InicioLeer; // Llama al entry (se bloquea hasta que Sched lo acepta)
    // ... Usa la BD ...
    Sched.FinLeer; // Notifica el fin
End loop;

// Escritor
Loop
    Sched.InicioEscribir; // Se bloquea hasta que Sched lo acepta (numLect=0)
    // ... Usa la BD ...
    Sched.FinEscribir; // Notifica el fin
End loop;
